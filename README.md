1. Credit card applications
 
•	Commercial banks receive a lot of applications for credit cards. Many of them get rejected for many reasons, like high loan balances, low income levels, or too many inquiries on an individual's credit report, for example. Manually analysing these applications is mundane, error-prone, and time-consuming (and time is money!). Luckily, this task can be automated with the power of machine learning and pretty much every commercial bank does so nowadays. In this notebook, we will build an automatic credit card approval predictor using machine learning techniques, just like the real banks do.

•	We'll use the Credit Card Approval dataset from the UCI Machine Learning Repository. The structure of this notebook is as follows:


•	First, we will start off by loading and viewing the dataset.
•	We will see that the dataset has a mixture of both numerical and non-numerical features, that it contains values from different ranges, plus that it contains a number of missing entries.
•	We will have to pre-process the dataset to ensure the machine learning model we choose can make good predictions.
•	After our data is in good shape, we will do some exploratory data analysis to build our intuitions.
Finally, we will build a machine learning model that can predict if an individual's application for a credit card will be accepted.




2. Movie Recommendation
3. 
•	GroupLens Research has collected and made available rating data sets from the MovieLens web site (http://movielens.org). The data sets were collected over various periods of time, depending on the size of the set.

Types of recommendation system
•	Popularity Based
It keeps a track of view counts for each movie/video and then lists movies based on views in descending order.

•	Content Based
This type of recommendation systems, takes in a movie that a user currently likes as input. Then it analysis the contents of the movie to find out other movies which have similar content. Then it ranks similar movies according to their similarity scores and recommends the most relevant movies to the user.

•	Collaborative filtering
In other words, the recommendations get filtered based on the collaboration between similar user’s preferences.
In this notebook we are going to implement content based recommendation system.




3. Prediction Heart Disease using Machine Learning
4. 
Thus preventing Heart diseases has become more than necessary. Good data-driven systems for predicting heart diseases can improve the entire research and prevention process, making sure that more people can live healthy lives. This is where Machine Learning comes into play. Machine Learning helps in predicting the Heart diseases, and the predictions made are quite accurate.
The project involved analysis of the heart disease patient dataset with proper data processing. Then, different models were trained and predictions are made with different algorithms KNN, Random Forest, Logistic Regression etc. 

I've used a variety of Machine Learning algorithms, implemented in Python, to predict the presence of heart disease in a patient. This is a classification problem, with input features as a variety of parameters, and the target variable as a binary variable, predicting whether heart disease is present or not.

•	The project involves following steps and more:
•	Data Exploration (exploratory data analysis or EDA)
•	Heart Disease Frequency according to Gender
•	Model Comparision
•	Tuning models with with RandomizedSearchCV
•	Tuning a model with GridSearchCV
•	Evaluating a classification model, beyond accuracy
•	Experimentation




4. Explore-Weather-Trends
5. 
Udacity Data Analyst Degree - Project I
•	Overview
In this project, I will analyze local and global temperature data and compare the temperature trends where I live to overall global temperature trends.
•	What Software Do I need?
To complete this project, i'll require the following softwares:
•	SQL
•	Excel
•	Extracting Data
To start I wrote an SQL query to retrieve all the temperature data from:
•	Local Database (Agra)
•	Global Database
Upon retrieving the data, it was extracted on a CSV file for further evaluation.
•	Data Selection & Manipulation
Once the data has been extracted on CSV, it was possible to further evaluate the data on Excel. To provide a more accurate and useful dataset for comparison a range of the common years only was chosen.
Moreover, due to fluctuations in yearly averages, the data was evaluated considering moving averages (7-years) to provide smoother results during data visualization.
•	Data Visualization




5. Investigate_dataset
6. 
•	It contains movie datasets listed by Imdb. In this, We start doing project using IMDB movie datasets.
•	It contains 10000 records and number of columns is 21.The given dataset could be analysed and it could help to reach some important information about those given data. Following are the points which could be analysed using the visualization of the datasets.
	we can find the most profitable movie
	we can find the average runtime of those movies over years
	we can find the genre which is mostly watched
	we can also find the highest and lowest budget movies
	 we can find the max an min revenue
####Unordered list (*)
